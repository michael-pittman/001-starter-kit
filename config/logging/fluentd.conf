# Fluentd Configuration for AI Starter Kit
# Centralized logging configuration for container logs

# =============================================================================
# INPUT SOURCES
# =============================================================================

# Docker container logs
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# System logs
<source>
  @type tail
  path /var/log/messages,/var/log/syslog
  pos_file /var/log/fluentd-syslog.log.pos
  tag system.logs
  format syslog
</source>

# Application-specific logs
<source>
  @type tail
  path /var/log/ai-starter-kit/*.log
  pos_file /var/log/fluentd-app.log.pos
  tag app.logs
  format json
  time_format %Y-%m-%d %H:%M:%S
</source>

# =============================================================================
# FILTERS AND PROCESSING
# =============================================================================

# Add environment and service metadata
<filter **>
  @type record_transformer
  <record>
    environment "#{ENV['ENVIRONMENT'] || 'unknown'}"
    stack_name "#{ENV['STACK_NAME'] || 'ai-starter-kit'}"
    instance_id "#{ENV['INSTANCE_ID'] || 'unknown'}"
    timestamp ${time}
  </record>
</filter>

# Parse application logs
<filter app.logs>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

# Extract container information
<filter docker.**>
  @type record_transformer
  <record>
    container_name ${record["container_name"]}
    container_id ${record["container_id"]}
    service ${record["container_name"].split("-")[0]}
  </record>
</filter>

# Security log processing
<filter **>
  @type grep
  <regexp>
    key message
    pattern /(ERROR|WARN|SECURITY|AUDIT)/i
  </regexp>
  tag security.events
</filter>

# Performance metrics extraction
<filter **>
  @type record_transformer
  enable_ruby true
  <record>
    log_level ${record["level"] || "info"}
    response_time ${record["response_time"] || 0}
    memory_usage ${record["memory_usage"] || 0}
    cpu_usage ${record["cpu_usage"] || 0}
  </record>
</filter>

# =============================================================================
# OUTPUT DESTINATIONS
# =============================================================================

# CloudWatch Logs (Production)
<match **>
  @type cloudwatch_logs
  log_group_name "/aws/ai-starter-kit/#{ENV['ENVIRONMENT']}"
  log_stream_name "#{ENV['INSTANCE_ID']}-#{ENV['CONTAINER_NAME']}"
  region "#{ENV['AWS_REGION'] || 'us-east-1'}"
  auto_create_stream true
  retention_in_days 30
  
  <format>
    @type json
  </format>
  
  <buffer>
    @type file
    path /var/log/fluentd-buffer/cloudwatch
    flush_mode interval
    flush_interval 5s
    chunk_limit_size 1m
    queue_limit_length 32
    retry_forever false
    retry_max_times 5
  </buffer>
</match>

# Elasticsearch (Alternative)
<match **>
  @type elasticsearch
  host "#{ENV['ELASTICSEARCH_HOST'] || 'localhost'}"
  port "#{ENV['ELASTICSEARCH_PORT'] || 9200}"
  index_name "ai-starter-kit-#{ENV['ENVIRONMENT']}"
  type_name "_doc"
  
  <buffer>
    @type file
    path /var/log/fluentd-buffer/elasticsearch
    flush_mode interval
    flush_interval 10s
    chunk_limit_size 2m
    queue_limit_length 64
  </buffer>
</match>

# Local file backup
<match **>
  @type file
  path /var/log/ai-starter-kit/aggregated.log
  append true
  time_slice_format %Y%m%d
  time_slice_wait 10m
  compress gzip
  
  <format>
    @type json
  </format>
  
  <buffer time>
    timekey 1h
    timekey_wait 10m
    path /var/log/fluentd-buffer/file
  </buffer>
</match>

# =============================================================================
# MONITORING AND HEALTH
# =============================================================================

# Fluentd monitoring
<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

# Health check endpoint
<source>
  @type http
  port 9880
  bind 0.0.0.0
  body_size_limit 32m
  keepalive_timeout 10s
</source>