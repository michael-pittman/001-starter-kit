# Modern Docker Compose format (no version field required)
# Uses the Compose Specification (latest)

# Enhanced GPU-Optimized Docker Compose Configuration
# Optimized for NVIDIA T4 GPUs on g4dn.xlarge instances
# Supports: DeepSeek-R1:8B, Qwen2.5-VL:7B, Snowflake-Arctic-Embed2:568M
# Features: EFS Integration, GPU Monitoring, Performance Optimization

# =============================================================================
# SHARED VOLUMES WITH EFS INTEGRATION
# =============================================================================
volumes:
  n8n_storage:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/n8n"
  postgres_storage:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/postgres"
  ollama_storage:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/ollama"
  qdrant_storage:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/qdrant"
  shared_storage:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/shared"
  crawl4ai_cache:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/crawl4ai/cache"
  crawl4ai_storage:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${EFS_DNS},nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,fsc,regional"
      device: ":/crawl4ai/storage"

# =============================================================================
# OPTIMIZED NETWORKS
# =============================================================================
networks:
  ai_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
    driver_opts:
      com.docker.network.driver.mtu: 9000  # Jumbo frames for better performance

# =============================================================================
# SHARED CONFIGURATIONS
# =============================================================================
x-gpu-config: &gpu-config
  runtime: nvidia
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
    - NVIDIA_DRIVER_CAPABILITIES=all
    - CUDA_VISIBLE_DEVICES=all
    - CUDA_DEVICE_ORDER=PCI_BUS_ID
  devices:
    - /dev/nvidia0:/dev/nvidia0
    - /dev/nvidia-uvm:/dev/nvidia-uvm
    - /dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools
    - /dev/nvidiactl:/dev/nvidiactl

x-logging-config: &logging-config
  logging:
    driver: "json-file"
    options:
      max-size: "100m"
      max-file: "5"

x-restart-policy: &restart-policy
  restart: unless-stopped

# =============================================================================
# SERVICE DEFINITIONS
# =============================================================================
services:
  # ---------------------------------------------------------------------------
  # PostgreSQL - Optimized for g4dn.xlarge (16GB RAM, 4 vCPUs)
  # ---------------------------------------------------------------------------
  postgres:
    <<: [*logging-config, *restart-policy]
    image: postgres:16.1-alpine3.19
    container_name: postgres-gpu
    hostname: postgres
    user: "70:70"  # postgres user in alpine
    networks:
      - ai_network
    security_opt:
      - no-new-privileges:true
    read_only: false  # PostgreSQL needs write access
    tmpfs:
      - /tmp:noexec,nosuid,size=1g
    ports:
      - "5432:5432"
    environment:
      # Basic PostgreSQL configuration
      - POSTGRES_DB=${POSTGRES_DB:-n8n}
      - POSTGRES_USER=${POSTGRES_USER:-n8n}
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
      
      # Performance optimizations for g4dn.xlarge
      - POSTGRES_MAX_CONNECTIONS=200
      - POSTGRES_SHARED_BUFFERS=2GB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=6GB
      - POSTGRES_WORK_MEM=16MB
      - POSTGRES_MAINTENANCE_WORK_MEM=256MB
      - POSTGRES_CHECKPOINT_COMPLETION_TARGET=0.9
      - POSTGRES_WAL_BUFFERS=64MB
      - POSTGRES_RANDOM_PAGE_COST=1.1
      - POSTGRES_EFFECTIVE_IO_CONCURRENCY=200
      
      # Connection pooling with PgBouncer
      - POSTGRES_POOL_MODE=transaction
      - POSTGRES_POOL_SIZE=25
      - POSTGRES_POOL_RESERVE=5
      
      # Connection and query optimization
      - POSTGRES_MAX_WAL_SIZE=2GB
      - POSTGRES_MIN_WAL_SIZE=1GB
      - POSTGRES_AUTOVACUUM_MAX_WORKERS=3
      - POSTGRES_AUTOVACUUM_NAPTIME=20s
    
    command: [
      "postgres",
      "-c", "shared_preload_libraries=pg_stat_statements",
      "-c", "max_connections=200",
      "-c", "shared_buffers=2GB",
      "-c", "effective_cache_size=6GB",
      "-c", "work_mem=16MB",
      "-c", "maintenance_work_mem=256MB",
      "-c", "checkpoint_completion_target=0.9",
      "-c", "wal_buffers=64MB",
      "-c", "random_page_cost=1.1",
      "-c", "effective_io_concurrency=200",
      "-c", "max_wal_size=2GB",
      "-c", "min_wal_size=1GB",
      "-c", "log_statement=ddl",
      "-c", "log_min_duration_statement=1000",
      "-c", "autovacuum_max_workers=3"
    ]
    
    volumes:
      - postgres_storage:/var/lib/postgresql/data
      - shared_storage:/shared
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U ${POSTGRES_USER:-n8n} -d ${POSTGRES_DB:-n8n} && psql -U ${POSTGRES_USER:-n8n} -d ${POSTGRES_DB:-n8n} -c 'SELECT 1;' > /dev/null"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    
    deploy:
      resources:
        limits:
          memory: 2G  # Reduced from 3G
          cpus: '0.4'  # Optimized for 85% total allocation
        reservations:
          memory: 1G  # Reduced from 1.5G
          cpus: '0.2'  # Optimized for 85% total allocation

  # ---------------------------------------------------------------------------
  # n8n - Workflow Automation Platform
  # ---------------------------------------------------------------------------
  n8n:
    <<: [*logging-config, *restart-policy]
    image: n8nio/n8n:1.19.4
    container_name: n8n-gpu
    hostname: n8n
    user: "1000:1000"  # n8n user
    networks:
      - ai_network
    security_opt:
      - no-new-privileges:true
    read_only: false  # n8n needs write access for workflows
    tmpfs:
      - /tmp:noexec,nosuid,size=512m
    ports:
      - "5678:5678"
    environment:
      # Basic n8n configuration
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB:-n8n}
      - DB_POSTGRESDB_USER=${POSTGRES_USER:-n8n}
      - DB_POSTGRESDB_PASSWORD_FILE=/run/secrets/postgres_password
      
      # n8n specific settings
      - N8N_HOST=${N8N_HOST:-0.0.0.0}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=${WEBHOOK_URL:-http://localhost:5678}
      
      # Security and encryption
      - N8N_ENCRYPTION_KEY_FILE=/run/secrets/n8n_encryption_key
      - N8N_USER_MANAGEMENT_JWT_SECRET_FILE=/run/secrets/n8n_jwt_secret
      
      # CORS - Secure configuration
      - N8N_CORS_ENABLE=${N8N_CORS_ENABLE:-true}
      - N8N_CORS_ALLOWED_ORIGINS=${N8N_CORS_ALLOWED_ORIGINS:-https://n8n.yourdomain.com}
      - N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=${N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE:-false}
      
      # Performance optimizations
      - N8N_PAYLOAD_SIZE_MAX=16
      - N8N_METRICS=true
      - N8N_LOG_LEVEL=info
      - N8N_LOG_OUTPUT=console
      
      # AI integration settings
      - N8N_AI_ENABLED=true
      - OLLAMA_BASE_URL=http://ollama:11434
      - QDRANT_URL=http://qdrant:6333
      
      # Instance information
      - INSTANCE_TYPE=${INSTANCE_TYPE:-g4dn.xlarge}
      - GPU_TYPE=nvidia-t4
      - DEPLOYMENT_MODE=gpu-optimized
    
    volumes:
      - n8n_storage:/home/node/.n8n
      - shared_storage:/shared
    
    depends_on:
      postgres:
        condition: service_healthy
    
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5678/healthz && curl -f http://localhost:5678/api/v1/workflows > /dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    
    deploy:
      resources:
        limits:
          memory: 1.5G  # Reduced from 2G
          cpus: '0.4'  # Optimized for 85% total allocation
        reservations:
          memory: 512M
          cpus: '0.2'  # Optimized for 85% total allocation

  # ---------------------------------------------------------------------------
  # Qdrant - Vector Database with GPU Optimizations
  # ---------------------------------------------------------------------------
  qdrant:
    <<: [*logging-config, *restart-policy]
    image: qdrant/qdrant:v1.7.3
    container_name: qdrant-gpu
    hostname: qdrant
    networks:
      - ai_network
    ports:
      - "6333:6333"
      - "6334:6334"
    environment:
      # Service configuration
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__ENABLE_CORS=true
      
      # Performance optimizations for GPU instance
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=8
      - QDRANT__STORAGE__PERFORMANCE__MAX_OPTIMIZATION_THREADS=4
      - QDRANT__STORAGE__PERFORMANCE__SEARCH_THREADS=4
      
      # Storage configuration
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__STORAGE__SNAPSHOTS_PATH=/qdrant/snapshots
      - QDRANT__STORAGE__TEMP_PATH=/qdrant/temp
      
      # Optimizer settings
      - QDRANT__STORAGE__OPTIMIZERS__VACUUM_MIN_VECTOR_NUMBER=1000
      - QDRANT__STORAGE__OPTIMIZERS__DEFAULT_SEGMENT_NUMBER=8
      - QDRANT__STORAGE__OPTIMIZERS__MAX_SEGMENT_SIZE=200000
      - QDRANT__STORAGE__OPTIMIZERS__MEMMAP_THRESHOLD=50000
      
      # Memory optimizations
      - QDRANT__STORAGE__PERFORMANCE__MAX_INDEXING_THREADS=4
      - QDRANT__STORAGE__WAL__WAL_CAPACITY_MB=256
    volumes:
      - qdrant_storage:/qdrant/storage
      - shared_storage:/qdrant/shared:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:6333/healthz && curl -f http://localhost:6333/collections > /dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G  # Reduced from 3G
          cpus: '0.4'  # Optimized for 85% total allocation
        reservations:
          memory: 1G
          cpus: '0.2'  # Optimized for 85% total allocation

  # ---------------------------------------------------------------------------
  # Ollama - GPU-Optimized AI Model Server
  # ---------------------------------------------------------------------------
  ollama:
    <<: [*gpu-config, *logging-config, *restart-policy]
    image: ollama/ollama:0.1.17
    container_name: ollama-gpu
    hostname: ollama
    networks:
      - ai_network
    ports:
      - "11434:11434"
    environment:
      # Ollama configuration
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=${OLLAMA_ORIGINS:-http://localhost:*,https://n8n.yourdomain.com}
      - OLLAMA_DEBUG=0
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_LOAD_TIMEOUT=300s
      
      # GPU optimizations for T4 (16GB VRAM) - Adjusted
      - OLLAMA_GPU_MEMORY_FRACTION=0.85  # Reduced from 0.90
      - OLLAMA_MAX_LOADED_MODELS=2  # Reduced from 3
      - OLLAMA_CONCURRENT_REQUESTS=4  # Reduced from 6
      - OLLAMA_NUM_PARALLEL=4  # Reduced from 6
      - OLLAMA_MAX_QUEUE=64  # Reduced from 128
      
      # Performance optimizations - Enhanced for T4
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_KV_CACHE_TYPE=f16
      - OLLAMA_USE_MLOCK=1
      - OLLAMA_NUMA=1
      - OLLAMA_TENSOR_PARALLEL_SIZE=1
      - OLLAMA_PIPELINE_PARALLEL_SIZE=1
      
      # Model-specific optimizations - T4 Tuned
      - OLLAMA_REQUEST_TIMEOUT=600s
      - OLLAMA_CONTEXT_LENGTH=8192
      - OLLAMA_BATCH_SIZE=1024
      - OLLAMA_THREADS=8
      - OLLAMA_MAX_TOKENS_PER_BATCH=2048
      
      # Memory and performance tuning
      - OLLAMA_MEMORY_POOL_SIZE=14GB
      - OLLAMA_CACHE_SIZE=2GB
      - OLLAMA_PREFILL_BATCH_SIZE=512
      - OLLAMA_DECODE_BATCH_SIZE=256
      
      # T4-specific CUDA optimizations
      - CUDA_CACHE_PATH=/tmp/cuda_cache
      - CUDA_LAUNCH_BLOCKING=0
      - NCCL_DEBUG=WARN
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
    volumes:
      - ollama_storage:/root/.ollama
      - shared_storage:/shared:ro
    tmpfs:
      - /tmp:size=2G
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags && curl -f http://localhost:11434/api/version > /dev/null || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 6G  # Reduced from 8G
          cpus: '2.0'  # Reduced from 1.5 but increased share as primary service
        reservations:
          memory: 4G
          cpus: '1.5'  # Reduced from 1.0 but increased share

  # ---------------------------------------------------------------------------
  # Model Initialization Service - Downloads and optimizes AI models
  # ---------------------------------------------------------------------------
  ollama-model-init:
    <<: [*gpu-config, *logging-config]
    image: ollama/ollama:0.1.17
    container_name: ollama-model-init
    networks:
      - ai_network
    environment:
      - OLLAMA_HOST=ollama:11434
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
    volumes:
      - ollama_storage:/root/.ollama
      - shared_storage:/shared
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: /bin/bash
    command:
      - "-c"
      - |
        set -euo pipefail
        
        echo "=== AI Model Initialization for GPU-Optimized Deployment ==="
        echo "Target GPU: NVIDIA T4 (16GB VRAM)"
        echo "Instance: g4dn.xlarge"
        echo "Models: DeepSeek-R1:8B, Qwen2.5-VL:7B, Snowflake-Arctic-Embed2:568M"
        
        # Wait for Ollama to be ready
        echo "Waiting for Ollama service..."
        sleep 30
        
        # Function to check if model exists
        model_exists() {
            ollama list | grep -q "$$1" || return 1
        }
        
        # Function to create optimized Modelfile
        create_optimized_modelfile() {
            local model_name="$$1"
            local base_model="$$2"
            local context_length="$$3"
            local num_gpu="$$4"
            local system_prompt="$$5"
            
            cat > "/tmp/Modelfile.$$model_name" << EOF
        FROM $$base_model
        
        # T4 GPU optimizations (16GB VRAM)
        PARAMETER num_ctx $$context_length
        PARAMETER num_batch 512
        PARAMETER num_gpu $$num_gpu
        PARAMETER num_thread 8
        PARAMETER num_predict 2048
        PARAMETER temperature 0.7
        PARAMETER top_p 0.9
        PARAMETER top_k 40
        PARAMETER repeat_penalty 1.1
        PARAMETER rope_freq_base 10000
        PARAMETER rope_freq_scale 1.0
        PARAMETER mirostat 0
        PARAMETER mirostat_eta 0.1
        PARAMETER mirostat_tau 5.0
        PARAMETER penalize_newline true
        
        # Memory optimizations
        PARAMETER use_mlock true
        PARAMETER use_mmap true
        PARAMETER numa true
        
        SYSTEM "$$system_prompt"
        EOF
        }
        
        echo "=== 1. DeepSeek-R1:8B - Reasoning and Problem Solving ==="
        if ! model_exists "deepseek-r1:8b"; then
            echo "Downloading DeepSeek-R1:8B..."
            ollama pull deepseek-r1:8b || echo "WARNING: Failed to pull deepseek-r1:8b"
        fi
        
        if model_exists "deepseek-r1:8b"; then
            echo "Creating optimized DeepSeek-R1:8B configuration..."
            create_optimized_modelfile \
                "deepseek-r1-optimized" \
                "deepseek-r1:8b" \
                "8192" \
                "1" \
                "You are DeepSeek-R1, an advanced reasoning AI optimized for complex problem-solving, logical analysis, and step-by-step thinking. You excel at breaking down complex problems into manageable steps and providing clear, reasoned solutions."
            
            ollama create deepseek-r1:8b-optimized -f /tmp/Modelfile.deepseek-r1-optimized || echo "WARNING: Failed to create optimized DeepSeek-R1"
            echo "✓ DeepSeek-R1:8B optimization completed"
        fi
        
        echo "=== 2. Qwen2.5-VL:7B - Vision-Language Understanding ==="
        if ! model_exists "qwen2.5:7b"; then
            echo "Downloading Qwen2.5:7B (base model for VL)..."
            ollama pull qwen2.5:7b || echo "WARNING: Failed to pull qwen2.5:7b"
        fi
        
        if model_exists "qwen2.5:7b"; then
            echo "Creating optimized Qwen2.5-VL:7B configuration..."
            create_optimized_modelfile \
                "qwen25-vl-optimized" \
                "qwen2.5:7b" \
                "6144" \
                "1" \
                "You are Qwen2.5-VL, a multimodal AI capable of understanding both text and visual content. You excel at image analysis, visual question answering, and connecting visual information with textual context."
            
            ollama create qwen2.5:7b-vl-optimized -f /tmp/Modelfile.qwen25-vl-optimized || echo "WARNING: Failed to create optimized Qwen2.5-VL"
            echo "✓ Qwen2.5-VL:7B optimization completed"
        fi
        
        echo "=== 3. Snowflake-Arctic-Embed2:568M - Embedding Generation ==="
        if ! model_exists "snowflake-arctic-embed2"; then
            echo "Downloading Snowflake-Arctic-Embed2..."
            # Note: This model might not be available in standard Ollama registry
            # We'll use a similar embedding model as fallback
            ollama pull mxbai-embed-large:latest || echo "WARNING: Using mxbai-embed-large as fallback"
            
            if model_exists "mxbai-embed-large"; then
                echo "Using mxbai-embed-large as Arctic-Embed2 alternative..."
                create_optimized_modelfile \
                    "arctic-embed-optimized" \
                    "mxbai-embed-large:latest" \
                    "2048" \
                    "1" \
                    "You are an advanced embedding model optimized for semantic similarity, document retrieval, and vector search tasks."
                
                ollama create arctic-embed:optimized -f /tmp/Modelfile.arctic-embed-optimized || echo "WARNING: Failed to create optimized Arctic-Embed"
                echo "✓ Arctic-Embed (mxbai-embed-large) optimization completed"
            fi
        fi
        
        echo "=== 4. Additional Optimized Models ==="
        
        # Llama3.2 for general tasks
        if ! model_exists "llama3.2:3b"; then
            echo "Downloading Llama3.2:3B for general tasks..."
            ollama pull llama3.2:3b || echo "WARNING: Failed to pull llama3.2:3b"
        fi
        
        if model_exists "llama3.2:3b"; then
            create_optimized_modelfile \
                "llama32-optimized" \
                "llama3.2:3b" \
                "4096" \
                "1" \
                "You are Llama3.2, a capable and efficient AI assistant optimized for general-purpose tasks, conversation, and quick reasoning."
            
            ollama create llama3.2:3b-optimized -f /tmp/Modelfile.llama32-optimized || echo "WARNING: Failed to create optimized Llama3.2"
            echo "✓ Llama3.2:3B optimization completed"
        fi
        
        echo "=== Model Optimization Summary ==="
        echo "Available optimized models:"
        ollama list | grep -E "(optimized|embed)" || echo "No optimized models found"
        
        echo "=== GPU Memory Usage Check ==="
        nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits || echo "GPU memory check unavailable"
        
        # Create model performance test script
        cat > /shared/test-models.sh << 'EOF'
        #!/bin/bash
        echo "=== Testing Optimized Models ==="
        
        # Test DeepSeek-R1
        echo "Testing DeepSeek-R1:8B..."
        curl -s -X POST http://ollama:11434/api/generate \
          -H "Content-Type: application/json" \
          -d '{"model": "deepseek-r1:8b-optimized", "prompt": "Solve: 2x + 5 = 15", "stream": false}' | jq -r '.response' || echo "DeepSeek-R1 test failed"
        
        # Test Qwen2.5-VL
        echo "Testing Qwen2.5-VL:7B..."
        curl -s -X POST http://ollama:11434/api/generate \
          -H "Content-Type: application/json" \
          -d '{"model": "qwen2.5:7b-vl-optimized", "prompt": "Describe the capabilities of a vision-language model.", "stream": false}' | jq -r '.response' || echo "Qwen2.5-VL test failed"
        
        # Test embedding model
        echo "Testing embedding model..."
        curl -s -X POST http://ollama:11434/api/embeddings \
          -H "Content-Type: application/json" \
          -d '{"model": "arctic-embed:optimized", "prompt": "This is a test document for embedding generation."}' | jq '.embedding | length' || echo "Embedding test failed"
        
        echo "Model testing completed"
        EOF
        
        chmod +x /shared/test-models.sh
        
        echo "=== Model Initialization Completed ==="
        echo "All optimized models are ready for use"
        echo "Test script created at /shared/test-models.sh"
        
        # Keep the container running for a bit to ensure models are fully loaded
        sleep 60
        echo "Model initialization service completed successfully"

  # ---------------------------------------------------------------------------
  # GPU Monitoring Service
  # ---------------------------------------------------------------------------
  gpu-monitor:
    <<: [*gpu-config, *logging-config, *restart-policy]
    image: nvidia/cuda:12.4.1-devel-ubuntu22.04
    container_name: gpu-monitor
    hostname: gpu-monitor
    networks:
      - ai_network
    environment:
      - PYTHONUNBUFFERED=1
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
      - INSTANCE_ID=${INSTANCE_ID}
      - INSTANCE_TYPE=${INSTANCE_TYPE:-g4dn.xlarge}
    volumes:
      - shared_storage:/shared
      - /var/log:/host/var/log:ro
    command:
      - /bin/bash
      - -c
      - |
        apt-get update && apt-get install -y python3 python3-pip curl
        pip3 install nvidia-ml-py3 psutil boto3
        
        # Create GPU monitoring script
        cat > /usr/local/bin/gpu_monitor.py << 'EOF'
        #!/usr/bin/env python3
        import time
        import json
        import nvidia_ml_py3 as nvml
        import psutil
        from datetime import datetime
        
        nvml.nvmlInit()
        
        while True:
            try:
                # GPU metrics
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                mem_info = nvml.nvmlDeviceGetMemoryInfo(handle)
                temp = nvml.nvmlDeviceGetTemperature(handle, nvml.NVML_TEMPERATURE_GPU)
                power = nvml.nvmlDeviceGetPowerUsage(handle) / 1000.0
                
                # System metrics
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                
                metrics = {
                    "timestamp": datetime.utcnow().isoformat(),
                    "gpu": {
                        "utilization": gpu_util.gpu,
                        "memory_used_mb": mem_info.used // 1024 // 1024,
                        "memory_total_mb": mem_info.total // 1024 // 1024,
                        "memory_utilization": (mem_info.used / mem_info.total) * 100,
                        "temperature_c": temp,
                        "power_draw_w": power
                    },
                    "system": {
                        "cpu_utilization": cpu_percent,
                        "memory_utilization": memory.percent,
                        "memory_used_gb": memory.used // 1024 // 1024 // 1024,
                        "memory_total_gb": memory.total // 1024 // 1024 // 1024
                    }
                }
                
                # Write metrics to shared storage
                with open("/shared/gpu_metrics.json", "w") as f:
                    json.dump(metrics, f, indent=2)
                
                print(f"GPU: {gpu_util.gpu}% | Mem: {(mem_info.used/mem_info.total)*100:.1f}% | Temp: {temp}°C | Power: {power:.1f}W")
                
                time.sleep(30)
                
            except Exception as e:
                print(f"Monitoring error: {e}")
                time.sleep(30)
        EOF
        
        chmod +x /usr/local/bin/gpu_monitor.py
        python3 /usr/local/bin/gpu_monitor.py
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.2'  # Optimized for 85% total allocation
        reservations:
          memory: 256M
          cpus: '0.1'  # Optimized for 85% total allocation

  # ---------------------------------------------------------------------------
  # Health Check Service
  # ---------------------------------------------------------------------------
  health-check:
    <<: [*logging-config, *restart-policy]
    image: curlimages/curl:8.5.0
    container_name: health-check
    hostname: health-check
    networks:
      - ai_network
    environment:
      - CHECK_INTERVAL=60
      - NOTIFICATION_WEBHOOK=${WEBHOOK_URL}
    volumes:
      - shared_storage:/shared
    command:
      - /bin/sh
      - -c
      - |
        while true; do
          echo "=== Health Check $(date) ==="
          
          # Check all services
          services=("n8n:5678/healthz" "ollama:11434/api/tags" "qdrant:6333/healthz" "postgres:5432")
          
          for service in "$${services[@]}"; do
            name=$$(echo $$service | cut -d: -f1)
            endpoint=$$(echo $$service | cut -d: -f2-)
            
            if curl -f -s "http://$$endpoint" > /dev/null; then
              echo "✓ $$name is healthy"
            else
              echo "✗ $$name is unhealthy"
            fi
          done
          
          # GPU health check
          if [ -f /shared/gpu_metrics.json ]; then
            gpu_temp=$$(cat /shared/gpu_metrics.json | grep -o '"temperature_c": [0-9]*' | cut -d' ' -f2)
            if [ "$$gpu_temp" -gt 85 ]; then
              echo "⚠ GPU temperature high: $${gpu_temp}°C"
            else
              echo "✓ GPU temperature normal: $${gpu_temp}°C"
            fi
          fi
          
          sleep $$CHECK_INTERVAL
        done
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # ---------------------------------------------------------------------------
  # Crawl4AI - Web Crawling with LLM-based Extraction
  # ---------------------------------------------------------------------------
  crawl4ai:
    <<: [*logging-config, *restart-policy]
    image: unclecode/crawl4ai:0.2.75
    container_name: crawl4ai-gpu
    hostname: crawl4ai
    networks:
      - ai_network
    ports:
      - "11235:11235"
    
    environment:
      # LLM Configuration for extraction strategies
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - TOGETHER_API_KEY=${TOGETHER_API_KEY}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - GEMINI_API_TOKEN=${GEMINI_API_TOKEN}
      
      # Ollama integration for local LLM processing
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      
      # Database connection
      - DATABASE_URL=postgresql://${POSTGRES_USER:-n8n}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-n8n}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      
      # Crawl4AI Configuration optimized for g4dn.xlarge
      - CRAWL4AI_HOST=0.0.0.0
      - CRAWL4AI_PORT=11235
      - CRAWL4AI_TIMEOUT_KEEP_ALIVE=600
      - CRAWL4AI_RELOAD=false
      
      # Security settings
      - CRAWL4AI_SECURITY_ENABLED=false
      - CRAWL4AI_JWT_ENABLED=false
      - CRAWL4AI_HTTPS_REDIRECT=false
      - CRAWL4AI_TRUSTED_HOSTS=["localhost","127.0.0.1","n8n","qdrant","ollama"]
      
      # Rate limiting for high-throughput scenarios
      - CRAWL4AI_RATE_LIMITING_ENABLED=true
      - CRAWL4AI_DEFAULT_LIMIT=2000/minute
      - CRAWL4AI_STORAGE_URI=memory://
      
      # Performance optimization for g4dn.xlarge (16GB RAM, 4 vCPUs)
      - CRAWL4AI_MEMORY_THRESHOLD_PERCENT=90.0
      - CRAWL4AI_BATCH_PROCESS_TIMEOUT=600.0
      - CRAWL4AI_STREAM_INIT_TIMEOUT=60.0
      
      # Browser optimization
      - CRAWL4AI_MAX_CONCURRENT_SESSIONS=4
      - CRAWL4AI_SESSION_TIMEOUT=300
      - CRAWL4AI_BROWSER_POOL_SIZE=2
      
      # Logging configuration
      - CRAWL4AI_LOG_LEVEL=INFO
      - CRAWL4AI_LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
      
      # Prometheus monitoring
      - CRAWL4AI_PROMETHEUS_ENABLED=true
      - CRAWL4AI_PROMETHEUS_ENDPOINT=/metrics
      - CRAWL4AI_HEALTH_CHECK_ENDPOINT=/health
      
      # Setup script configuration
      - ENABLE_MONITORING=true
    
    volumes:
      - shared_storage:/data/shared
      - /dev/shm:/dev/shm:rw,nosuid,nodev,exec,size=2g
      # Mount for browser cache and temporary files
      - crawl4ai_cache:/app/cache
      - crawl4ai_storage:/app/storage
    
    # Use the default crawl4ai command instead of custom script for now
    # command: crawl4ai
    
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11235/health || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s
    
    deploy:
      resources:
        limits:
          memory: 1.5G  # Reduced from 2G
          cpus: '0.4'  # Optimized for 85% total allocation
        reservations:
          memory: 1G
          cpus: '0.2'  # Optimized for 85% total allocation
    
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy

# =============================================================================
# DOCKER SECRETS CONFIGURATION
# =============================================================================
secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
  n8n_encryption_key:
    file: ./secrets/n8n_encryption_key.txt
  n8n_jwt_secret:
    file: ./secrets/n8n_jwt_secret.txt

# =============================================================================
# SERVICE STARTUP ORDER AND DEPENDENCIES
# =============================================================================
# Startup sequence:
# 1. postgres (foundation)
# 2. qdrant, n8n (depend on postgres)
# 3. ollama (independent GPU service)
# 4. ollama-model-init (depends on ollama)
# 5. gpu-monitor, health-check (monitoring services)

# =============================================================================
# RESOURCE ALLOCATION SUMMARY FOR g4dn.xlarge (OPTIMIZED)
# =============================================================================
# Total Resources: 4 vCPUs, 16GB RAM, 16GB T4 VRAM
# 
# CPU Allocation (Total: 3.4 vCPUs target - 85% utilization):
# - postgres: 0.4 vCPUs (10%)
# - n8n: 0.4 vCPUs (10%)
# - ollama: 2.0 vCPUs (50%) - primary compute user
# - qdrant: 0.4 vCPUs (10%)
# - crawl4ai: 0.4 vCPUs (10%)
# - gpu-monitor: 0.2 vCPUs (5%)
# - health-check: 0.1 vCPUs (2.5%)
# Total Allocated: 3.4 vCPUs (85% - optimal resource utilization)
# 
# Memory Allocation (Total: 16GB):
# - postgres: 2GB (12.5%)
# - n8n: 1.5GB (9.4%)
# - ollama: 6GB (37.5%) - primary memory user
# - qdrant: 2GB (12.5%)
# - crawl4ai: 1.5GB (9.4%)
# - gpu-monitor: 512MB (3.2%)
# - health-check: 128MB (0.8%)
# Total Allocated: 13.64GB (85.25% - leaves headroom for OS and bursting)
# 
# GPU Memory (T4 16GB):
# - ollama: ~13.6GB (85% of 16GB)
# - system reserve: ~2.4GB (15%)
#
# Network: All services on ai_network (172.20.0.0/16) with jumbo frames 